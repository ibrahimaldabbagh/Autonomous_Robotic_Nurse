# RoboNurse â€“ Autonomous Robotic Nursing Assistant

<div align="center">

**Intelligent Service Robot for Healthcare Environments**

*Navigation â€¢ Perception â€¢ Face Recognition â€¢ Voice Interaction â€¢ Dual HMI â€¢ Medicine & Food Delivery â€¢ Patient Monitoring*

<img src="images/1646784162494.jpg" alt="RoboNurse Robot" width="600"/>

[![ROS 2](https://img.shields.io/badge/ROS-2-blue.svg)](https://docs.ros.org/en/humble/)
[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

</div>

---

## ğŸ“‹ Table of Contents

1. [Overview](#-overview)
2. [System Mission](#-system-mission)
3. [Key Features](#-key-features)
4. [Example Mission Flow](#-example-mission-flow)
5. [System Architecture](#-system-architecture)
6. [Repository Structure](#-repository-structure)
7. [Software Modules](#-software-modules)
8. [Hardware & Firmware](#-hardware--firmware)
9. [Quick Start](#-quick-start)
10. [Development Workflow](#-development-workflow)
11. [Security & Safety](#-security--safety)
12. [Contributing](#-contributing)

---

## ğŸ¯ Overview

RoboNurse is a **ROS 2-based autonomous robotic nursing assistant** designed for safe patient assistance, HMI-driven service delivery, and advanced research in mobile perception and manipulation. Built to be modular, auditable, and safe for clinical-like settings, RoboNurse addresses the chronic shortage of nursing staff by automating repetitive, logistical tasks.

### Design Philosophy

- **Modularity**: Clear ROS 2 node boundaries with well-defined topic contracts
- **Safety-First**: Multiple layers of gating, watchdogs, and E-STOP handling
- **Portability**: ONNX models for inference on Jetson-class boards
- **Security**: Encrypted local face database for patient identity
- **Clinical-Grade**: Dual HMI system for operator oversight and patient interaction

---

## ğŸ¥ System Mission

Hospitals face increasing workloads and staff shortages. RoboNurse autonomously performs:

- âœ… **Medicine delivery** (bottles, blister packs, syringes)
- âœ… **Meal delivery** (trays, drinks, snacks)
- âœ… **Patient interaction** (speech + tablet interface)
- âœ… **Identity verification** (face recognition)
- âœ… **Room verification** (QR-based validation)
- âœ… **Vital signs monitoring** (heartbeat sensor)
- âœ… **Safe navigation** with human-aware obstacle avoidance
- âœ… **Live video streaming** for staff oversight

**Goal**: Offload repetitive logistics to enable nursing staff to focus on direct clinical care.

### ğŸ“¸ Robot in Action

<div align="center">
<img src="images/motion.gif" alt="Robot Movement Demo" width="600"/>
</div>

---

## ğŸŒŸ Key Features

### Perception & AI
- **YOLO-based Object Detection** (ONNX, CUDA-accelerated)
- **Face Recognition** with encrypted identity matching
- **Real-time Human Detection** for collision avoidance
- **Patient Status Monitoring** with temporal smoothing

### Navigation & Safety
- **Autonomous Path Planning** with SLAM/localization
- **Local Safety Planner** with IR sensor override
- **Human-Aware Movement** with dynamic replanning
- **Emergency Stop** (E-STOP) handling at hardware level

### Interaction Systems
- **Dual HMI Architecture**:
  - Operator interface for task assignment and monitoring
  - Patient interface for identity confirmation and service requests
- **Voice Interaction**: ASR (VOSK) and TTS (gTTS)
- **Video Streaming**: RTSP/WebRTC with recording capabilities

### Hardware Control
- **Mecanum Drive** with encoder-based odometry
- **Pan/Tilt Head** for camera positioning
- **Automated Dispensers** for medicine and food delivery
- **Sensor Suite**: IR, ultrasonic, bump sensors, heartbeat monitor

---

## ğŸ”„ Example Mission Flow

A typical delivery mission demonstrates full system integration:

### 1ï¸âƒ£ Task Assignment
Nurse selects task via **Operator HMI**:
> *"Deliver morning medication to Room 212 for patient Ahmed"*

### 2ï¸âƒ£ Autonomous Navigation
- Localizes within hospital ward
- Plans safe path avoiding obstacles
- Adjusts trajectory around humans
- Monitors IR sensors for emergency stops

### 3ï¸âƒ£ Room Identification
- Detects QR code near door
- Validates room number
- Cross-references with task data

### 4ï¸âƒ£ Patient Verification
- Captures face image
- Matches against encrypted database
- Confirms identity with name/voice
- **Halts if mismatch detected**

### 5ï¸âƒ£ Interaction & Confirmation
TTS greeting:
> *"Hello, I am RoboNurse. May I confirm your identity before delivering medication?"*

Patient responds via:
- Voice command (ASR)
- Touch input (Patient HMI)

### 6ï¸âƒ£ Item Delivery
- Opens internal compartment
- Presents medicine/food
- Logs delivery time and confirmation

### 7ï¸âƒ£ Vital Signs Check (Optional)
- Reads heartbeat sensor
- Transmits heart rate data
- Flags rhythm anomalies

### 8ï¸âƒ£ Mission Completion
- Logs task completion
- Sends report to operator
- Returns to docking station

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     OPERATOR HMI TABLET                     â”‚
â”‚           (Task Assignment â€¢ Video Feed â€¢ Logs)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ ROS2 Topics / WebRTC / REST
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ROBONURSE ROBOT                        â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Perception  â”‚  â”‚ Face Recog.  â”‚  â”‚  Voice (ASR/TTS)â”‚  â”‚
â”‚  â”‚ YOLO+Camera  â”‚  â”‚ ArcFace ONNX â”‚  â”‚  VOSK + gTTS    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                 â”‚                    â”‚            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Navigation & Local Planning             â”‚  â”‚
â”‚  â”‚         SLAM â€¢ Path Planning â€¢ Obstacle Avoidance    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚Hardware Controlâ”‚  â”‚Patient Statusâ”‚  â”‚ Video Streaming â”‚ â”‚
â”‚  â”‚Motorsâ€¢Actuatorsâ”‚  â”‚ QR â€¢ Vitals  â”‚  â”‚  RTSP/WebRTC   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                 PATIENT HMI TABLET                   â”‚   â”‚
â”‚  â”‚      (Identity Confirm â€¢ Service Request â€¢ Help)     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Repository Structure

```
Autonomous_Robotic_Nurse/
â”‚
â”œâ”€â”€ robonurse_nav/                    # Navigation & path planning
â”‚   â”œâ”€â”€ local_planner_node.py        # IR-based safety controller
â”‚   â””â”€â”€ launch/                       # Nav2 integration
â”‚
â”œâ”€â”€ robonurse_perception/             # Vision & object detection
â”‚   â”œâ”€â”€ perception_camera_node.py    # YOLO ONNX inference
â”‚   â””â”€â”€ models/                       # Detection models
â”‚
â”œâ”€â”€ robonurse_face_recognition/       # Patient identification
â”‚   â”œâ”€â”€ face_recognition_node.py     # Real-time matching
â”‚   â”œâ”€â”€ register_face.py             # Enrollment utility
â”‚   â””â”€â”€ db/                          # Encrypted embeddings
â”‚
â”œâ”€â”€ robonurse_voice/                  # Speech interaction
â”‚   â”œâ”€â”€ speech_asr_node.py           # VOSK speech-to-text
â”‚   â””â”€â”€ speech_tts_node.py           # gTTS text-to-speech
â”‚
â”œâ”€â”€ robonurse_hmi/                    # Human-machine interfaces
â”‚   â”œâ”€â”€ operator/                     # React-based operator UI
â”‚   â”œâ”€â”€ patient/                      # React-based patient UI
â”‚   â””â”€â”€ teleop_bridge_node.py        # Command gating
â”‚
â”œâ”€â”€ robonurse_patient_status/         # Vitals & room tracking
â”‚   â””â”€â”€ patient_status_node.py       # Status aggregation
â”‚
â”œâ”€â”€ robonurse_hw/                     # Hardware abstraction
â”‚   â”œâ”€â”€ motor_control_node.py        # Mecanum kinematics
â”‚   â”œâ”€â”€ wheel_odometry_node.py       # Encoder-based odometry
â”‚   â”œâ”€â”€ actuator_control_node.py     # Dispenser control
â”‚   â”œâ”€â”€ head_interact_bridge.py      # Pan/tilt servo bridge
â”‚   â”œâ”€â”€ firmware/
â”‚   â”‚   â”œâ”€â”€ mega_motor_control.ino   # Arduino Mega (motors)
â”‚   â”‚   â””â”€â”€ nano_head_control.ino    # Arduino Nano (head/audio)
â”‚   â””â”€â”€ scripts/                      # Hardware utilities
â”‚
â”œâ”€â”€ video_stream_node/                # Camera streaming
â”‚   â”œâ”€â”€ video_stream_node.py         # RTSP/WebRTC server
â”‚   â””â”€â”€ config/                       # Stream parameters
â”‚
â”œâ”€â”€ robonurse_interfaces/             # Custom ROS messages/services
â”‚   â”œâ”€â”€ msg/                          # Custom message types
â”‚   â””â”€â”€ srv/                          # Service definitions
â”‚
â””â”€â”€ images/                           # Documentation assets
    â”œâ”€â”€ 1646784162494.jpg            # Robot render
    â”œâ”€â”€ robot_motion.gif             # Movement demo
    â”œâ”€â”€ hmi_operator.png             # Operator UI screenshot
    â””â”€â”€ hmi_patient.png              # Patient UI screenshot
```

---

## ğŸ”§ Software Modules

### ğŸ¥ Perception System

#### `perception_camera_node`
**Package**: `robonurse_perception`

**Purpose**: Real-time visual understanding using YOLO-based detection

**Key Behavior**:
- Publishes `/camera/image_raw` (sensor_msgs/Image)
- Publishes `/people/detections` (vision_msgs/Detection2DArray)
- CUDA-accelerated inference on Jetson
- Configurable confidence and NMS thresholds

**Parameters**:
```yaml
model_path: "models/yolov5.onnx"
classes_path: "models/classes.txt"
input_size: 640
conf_threshold: 0.5
nms_threshold: 0.4
use_cuda: true
```

---

#### `face_recognition_node`
**Package**: `robonurse_face_recognition`

**Purpose**: Patient identity verification with encrypted database

**Key Behavior**:
- Subscribes to `/camera/image_raw` and `/people/detections`
- Computes L2-normalized face embeddings (ArcFace ONNX)
- Matches against encrypted Fernet database
- Publishes `/people/identity` with JSON payload:
  ```json
  {"id": "patient_01", "distance": 0.32}
  ```

**Security**: Symmetric encryption with Fernet keys. Restrict key permissions.

**Enrollment**:
```bash
python register_face.py \
  --image images/patient01.jpg \
  --id patient_01 \
  --model models/arcface.onnx \
  --db /var/robonurse/db/faces.enc \
  --key /var/robonurse/db/fernet.key
```

---

### ğŸ¤ Voice Interaction

#### `speech_asr_node`
**Package**: `robonurse_voice`

**Purpose**: Offline speech recognition using VOSK

**Key Behavior**:
- Captures microphone audio
- Publishes `/speech/text` (std_msgs/String)
- Keyword spotting for commands
- No internet dependency

**Requirements**: VOSK model on disk (specify language)

---

#### `speech_tts_node`
**Package**: `robonurse_voice`

**Purpose**: Text-to-speech synthesis

**Key Behavior**:
- Subscribes to `/speech/say` (std_msgs/String)
- Uses gTTS for natural voice generation
- Plays audio via mpg123 for low latency

---

### ğŸ—ºï¸ Navigation System

#### `local_planner_node`
**Package**: `robonurse_nav`

**Purpose**: Fast local safety controller with sensor override

**Key Behavior**:
- Subscribes to `/sensor/ir` (Range) and `/nav_cmd_vel` (Twist)
- Publishes safe `/cmd_vel` to actuators
- **Emergency stop** if IR detects obstacles < `ir_stop_distance`
- Hysteresis prevents oscillation

**Integration**: Works parallel to Nav2 for safety-critical short-range stops

**Parameters**:
```yaml
ir_stop_distance: 0.3  # meters
ir_resume_distance: 0.5  # meters
```

---

### ğŸ® Human-Machine Interfaces

#### `teleop_bridge_node`
**Package**: `robonurse_hmi`

**Purpose**: Gate and relay operator commands with mode enforcement

**Key Behavior**:
- Subscribes to `/joy_vel`, `/robot/mode_switch`, `/manipulator/control`
- Maintains `current_mode` ('manual'/'autonomous')
- **Only relays manual commands in manual mode**
- Publishes to `/cmd_vel`, `/system/manipulator_action`, `/system/emergency_trigger`

**Safety**: Prevents manual override during autonomous missions

---

#### Operator HMI
**Location**: `robonurse_hmi/operator/`

**Features**:
- Task assignment interface
- Live video feed (WebRTC)
- Robot status dashboard
- Mission logs and history
- Manual override controls


<div align="center">
<img src="images/OHMI2.png" alt="Operator HMI" width="600"/>
</div>
---

#### Patient HMI
**Location**: `robonurse_hmi/patient/`

**Features**:
- Identity confirmation
- Service requests (food, water, nurse call)
- Emergency alert button
- Medication acceptance
- Health instructions display

<div align="center">
<img src="images/PHMI1.png" alt="Patient HMI" width="600"/>
</div>
---

### ğŸ¤– Hardware Control

#### `motor_control_node`
**Package**: `robonurse_hw`

**Purpose**: Translate `/cmd_vel` to wheel velocities for Arduino Mega

**Key Behavior**:
- Converts Twist to 4-wheel speeds (mecanum kinematics)
- Sends binary serial packets: header `0xAA 0x55` + cmd + CRC8
- **Watchdog**: sends stop if no `/cmd_vel` within timeout

**Parameters**:
```yaml
serial_port: "/dev/ttyACM0"
baudrate: 115200
wheel_radius: 0.0762  # meters
base_width: 0.42  # meters
base_length: 0.38  # meters
max_speed: 1.0  # m/s
watchdog_timeout: 0.5  # seconds
```

---

#### `wheel_odometry_node`
**Package**: `robonurse_hw`

**Purpose**: Parse encoder telemetry and publish odometry

**Key Behavior**:
- Parses packets from Mega (header `0x55 0xAA`, pkt_id `0x10`)
- Computes delta encoder distances
- Estimates velocities (vx, vy, Ï‰z) via mecanum kinematics
- Publishes `/odom` (nav_msgs/Odometry)

**Note**: Position integration left as zero; provides velocity-only odometry for fusion

---

#### `actuator_control_node`
**Package**: `robonurse_hw`

**Purpose**: Service interface for medicine/food dispensing

**Service**: `/dispense/item` (robonurse_interfaces.srv.DispenseItem)

**Key Behavior**:
- Sends serial commands to Arduino Mega
- Waits for ACK packet
- Logs dispense events with timestamps

---

#### `head_interact_bridge`
**Package**: `robonurse_hw`

**Purpose**: Control pan/tilt servos and audio via Arduino Nano

**Topics**:
- Publishes: `head/pan_command`, `head/tilt_command` (Int16)
- Subscribes: `head/pan_status` (feedback from Nano)

**Integration**: Uses rosserial for Arduino communication

---

### ğŸ“Š Patient Status

#### `patient_status_node`
**Package**: `robonurse_patient_status`

**Purpose**: Aggregate detections into high-level patient status

**Key Behavior**:
- Subscribes to `/people/detections`, `/sensor/heartbeat`, `/camera/qr`
- Applies temporal smoothing and priority selection
- Publishes `/patient/status` (e.g., "sitting", "lying", "needs_assistance")

---

### ğŸ“¹ Video Streaming

#### `video_stream_node`
**Package**: `video_stream_node`

**Purpose**: Low-latency video to operators

**Key Behavior**:
- Subscribes to `/camera/image_raw`
- Streams to RTSP URL via FFmpeg (H.264 encoding)
- Hardware acceleration on Jetson
- Services: `/video/start_recording`, `/video/stop_recording`

**Config**:
```yaml
stream_url: "rtsp://localhost:8554/robonurse"
codec: "h264_nvenc"  # Hardware encoding
bitrate: "2M"
framerate: 30
```

---

## ğŸ”© Hardware & Firmware

### Arduino Mega (`mega_motor_control.ino`)
**Responsibilities**:
- 4x motor driver control (PWM + direction)
- Encoder interrupts (quadrature)
- IR and ultrasonic sensor reading
- E-STOP monitoring
- Actuator sequences (dispensers)
- Serial telemetry (odometry packet `0x10`)

**Protocol**: Hostâ†’Mega packets start with `0xAA 0x55`, Megaâ†’Host with `0x55 0xAA`. CRC8 checksum validation.

**Pin Configuration**: Verify mappings match your hardware before deployment.

---

### Arduino Nano (`nano_head_control.ino`)
**Responsibilities**:
- Pan/tilt servo control (PWM)
- DFPlayer MP3 module control
- Rosserial subscriber loop
- Status feedback publishing

**Communication**: USB serial with rosserial bridge


---

## ğŸ” Security & Safety

### Patient Privacy
- âœ… Face database uses **Fernet symmetric encryption**
- âœ… Restrict key file permissions: `chmod 600 /var/robonurse/db/fernet.key`
- âœ… Consider HSM or keyring integration for production
- âœ… Log all access and modifications
- âœ… Implement data retention policies per HIPAA/GDPR

### Physical Safety
- âœ… **E-STOP must be tested** before each deployment
- âœ… Watchdog enforces stop commands on timeout
- âœ… Local planner overrides navigation for emergency stops
- âœ… Bump sensors provide hardware-level collision detection
- âœ… Test in controlled environment before clinical trials

### Network Security
- âœ… Use encrypted WebRTC/HTTPS for video streaming
- âœ… Implement authentication for operator HMI
- âœ… Firewall rules for ROS 2 DDS communication
- âœ… Regular security audits of dependencies

### Logging & Compliance
- âœ… Record all patient interactions with timestamps
- âœ… Maintain audit trail for dispensing events
- âœ… Anonymize logs for research/debugging
- âœ… Consent management for biometric data

---

## ğŸ“ˆ Future Enhancements

- [ ] Multi-robot coordination and fleet management
- [ ] Advanced manipulation with robotic arm integration
- [ ] Cloud integration for remote monitoring
- [ ] Machine learning for patient behavior prediction
- [ ] Integration with hospital EMR systems
- [ ] Natural language understanding for complex queries
- [ ] Autonomous elevator navigation
- [ ] Multi-floor SLAM mapping

---

## ğŸ‘¤ Author & Contact

**Ibrahim Al Dabbagh**  
ğŸ“§ eng.ibrahim.aldabbagh@gmail.com


---

<div align="center">

**RoboNurse** â€“ Advancing Healthcare Through Intelligent Robotics

*Built with â¤ï¸ for safer, more efficient patient care*

</div>